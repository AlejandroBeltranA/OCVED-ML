{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCVED_GSR_Trained_v2.4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroBeltranA/OCVED-ML/blob/master/OCVED_GSR_Trained_v2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiJIU9rbVOKr",
        "colab_type": "text"
      },
      "source": [
        "# Text Classification for OCVED\n",
        "\n",
        "This script details the process for generating the models used in \"Enhancing the Detection of Criminal Organizations in Mexico Using ML and NLP\" available at https://www.ocved.mx/\n",
        "\n",
        "This is 1 of 4 scripts describing this process. In this script we clean the text, use gold standard records of reclassified articles by annotators, build the machine learning models excluding the transformer models, and save the model used to classify the universe of articles.\n",
        "\n",
        "\n",
        "The below script uses training data generated by student RA's to classify whether an article is relevant to the OCVED project or not. The students selected based on mentions of cartel related violence. It includes mentions of drug seizures, shootouts, and other cartel related events. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_zIe_7mqw1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c9efb4b9-3393-4da3-c876-6712c0d8caff"
      },
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TLtyl1dq6u5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dd237da0-7e07-4eba-ce82-ed6859ee30fe"
      },
      "source": [
        "# Set cd\n",
        "%cd /content/drive/\n",
        "!ls\n",
        "#Install tqdm package for tracking progress\n",
        "!pip install tqdm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "'My Drive'\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94IOEMbUGMw",
        "colab_type": "text"
      },
      "source": [
        "# Section 1: Load and Clean \n",
        "\n",
        "There are three datasets used in this project. \n",
        "\n",
        "The first is \"OCVED_2010-2018.csv\" which containts 30,842 articles that students classified using the Brat annotation software. Students classified as \"Accept\" or \"Reject\" based on a list of paramters that distinguish between articles related to drug trafficking organizations, drugs, and government in Mexico. Articles accepted must have included a mention of an event associated with a dto. More information available at the project website. These articles were scraped from an online news repository and include a large collection of non-relevant articles, that is why we implemented the text classification step. These articles were collected from regional newspapers or non-national sources. \n",
        "\n",
        "The second is \"National_OCVED.csv\" which is a different set of articles that were manually downloaded by research assitants. These articles were identified as relevant at the source, and does not include non-relevant articles. This collection contains 29,995 articles collected from major newspapers in Mexico at the national level from 2000 through 2018. \n",
        "\n",
        "The third is \"correct_classification.csv\" which is a subset of 1 & 2 combined. In a previous iteration we identified 7,500 articles were the model and annotators did not agree. To increase the accuracy of the final model we implemented a human in the loop approach where these articles were reclassified by the annotators to confirm the correct classification. They were thus reviewed at the initial stage by the annotator, at a second stage by the machine, and a third stage again by the annotator. In addition, if the annotator was uncertain of the final classification these were reviewed by the researchers to confirm the correct classification. Given the multiple reviews and attention to these articles we classify them as \"Gold Standard of Record\" articles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccHo_O2RrEpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Packages used in this section.\n",
        "import glob\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCeYOAgGs7If",
        "colab_type": "text"
      },
      "source": [
        "First dataset. file_id contains the date of publication. label is the assigned tag. Excerpt is a subset of text annotated by students. Text is the full article.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-h4VGEX19RD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "380f80cd-b49e-4327-febf-ce54ed4328a5"
      },
      "source": [
        "df = pd.read_csv('My Drive/Data/OCVED/BRAT/OCVED_2010-2018.csv')\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>label</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20160926__550828948.txt</td>\n",
              "      <td>Reject</td>\n",
              "      <td>Reject 127 492\\tCIUDAD DE MÉXICO (El Universal...</td>\n",
              "      <td>\\nSeptember 26, 2016\\n|\\nPublication: \\n      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20161013__552467359.txt</td>\n",
              "      <td>Reject</td>\n",
              "      <td>Reject 125 341\\tNUEVA YORK (EFE). Michael Jack...</td>\n",
              "      <td>\\nOctober 13, 2016\\n|\\nPublication: \\n        ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20160209__518137112.txt</td>\n",
              "      <td>Reject</td>\n",
              "      <td>Reject 155 384\\tEn enero de 2016, los precios ...</td>\n",
              "      <td>\\nFebruary 09, 2016 (10:29)\\n|\\nPublication: \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20160817__546311869.txt</td>\n",
              "      <td>Reject</td>\n",
              "      <td>Reject 136 394\\t20160817.-El centro comercial ...</td>\n",
              "      <td>\\nAugust 17, 2016\\n|\\nPublication: \\n         ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20161129__557525748.txt</td>\n",
              "      <td>Reject</td>\n",
              "      <td>Reject 137 379\\tEl alcalde Mauricio Vila Dosal...</td>\n",
              "      <td>\\nNovember 29, 2016 (03:00)\\n|\\nPublication: \\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   file_id  ...                                               text\n",
              "0  20160926__550828948.txt  ...  \\nSeptember 26, 2016\\n|\\nPublication: \\n      ...\n",
              "1  20161013__552467359.txt  ...  \\nOctober 13, 2016\\n|\\nPublication: \\n        ...\n",
              "2  20160209__518137112.txt  ...  \\nFebruary 09, 2016 (10:29)\\n|\\nPublication: \\...\n",
              "3  20160817__546311869.txt  ...  \\nAugust 17, 2016\\n|\\nPublication: \\n         ...\n",
              "4  20161129__557525748.txt  ...  \\nNovember 29, 2016 (03:00)\\n|\\nPublication: \\...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSzLNoB2tBXC",
        "colab_type": "text"
      },
      "source": [
        "Count the number of accept & reject tags. The data is unbalanced towards reject. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjub81vBLn40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b51a3dc2-375a-419c-e2d9-f93a147d5ec6"
      },
      "source": [
        "count = df.groupby('label')['label'].count()\n",
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "Accept     7183\n",
              "Reject    23659\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LrtpT9EtGAY",
        "colab_type": "text"
      },
      "source": [
        "Dataset 2 is added here. file_id contains the data, label is the classification, and text is the full article. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU86lLnm6xfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "ea51b067-0e58-4c52-d795-4773ea3f6195"
      },
      "source": [
        "nat = pd.read_csv('My Drive/Data/OCVED/National/txt_docs/National_OCVED.csv')\n",
        "nat.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>file_id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 de Enero de 2000 \\nTranslation powered by Go...</td>\n",
              "      <td>20000105001_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n Las Margaritas, Chis., 5 Ene (N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4 de Enero de 2000 \\nTranslation powered by Go...</td>\n",
              "      <td>20000105002_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 4 Ene (NTX).- La Policí...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6 de Enero de 2000 \\nTranslation powered by Go...</td>\n",
              "      <td>20000106001_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6 de Enero de 2000 \\nTranslation powered by Go...</td>\n",
              "      <td>20000106002_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n Monterrey, NL., 6 Ene (NTX).- L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6 de Enero de 2000 \\nTranslation powered by Go...</td>\n",
              "      <td>20000106003_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                date  ...                                               text\n",
              "0  5 de Enero de 2000 \\nTranslation powered by Go...  ...  \\n es \\n \\n \\n Las Margaritas, Chis., 5 Ene (N...\n",
              "1  4 de Enero de 2000 \\nTranslation powered by Go...  ...  \\n es \\n \\n \\n México, 4 Ene (NTX).- La Policí...\n",
              "2  6 de Enero de 2000 \\nTranslation powered by Go...  ...  \\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...\n",
              "3  6 de Enero de 2000 \\nTranslation powered by Go...  ...  \\n es \\n \\n \\n Monterrey, NL., 6 Ene (NTX).- L...\n",
              "4  6 de Enero de 2000 \\nTranslation powered by Go...  ...  \\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPRbq4RvmuhW",
        "colab_type": "text"
      },
      "source": [
        "Combine the two data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzyvtnCp9ERX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "a0f75051-3d3d-4a80-b4ae-c4b46c3f4b71"
      },
      "source": [
        "data = []\n",
        "data.append(df)\n",
        "data.append(nat)\n",
        "frame = pd.concat(data, axis=0, ignore_index=True, sort=True).sort_values('file_id', ascending= True).drop(columns=['date', 'excerpt'])\n",
        "frame.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30842</th>\n",
              "      <td>20000105001_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n Las Margaritas, Chis., 5 Ene (N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30843</th>\n",
              "      <td>20000105002_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 4 Ene (NTX).- La Policí...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30844</th>\n",
              "      <td>20000106001_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30845</th>\n",
              "      <td>20000106002_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n Monterrey, NL., 6 Ene (NTX).- L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30846</th>\n",
              "      <td>20000106003_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   file_id  ...                                               text\n",
              "30842  20000105001_NAC.txt  ...  \\n es \\n \\n \\n Las Margaritas, Chis., 5 Ene (N...\n",
              "30843  20000105002_NAC.txt  ...  \\n es \\n \\n \\n México, 4 Ene (NTX).- La Policí...\n",
              "30844  20000106001_NAC.txt  ...  \\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...\n",
              "30845  20000106002_NAC.txt  ...  \\n es \\n \\n \\n Monterrey, NL., 6 Ene (NTX).- L...\n",
              "30846  20000106003_NAC.txt  ...  \\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2azn1OmfXhn",
        "colab_type": "text"
      },
      "source": [
        "We have a total of 60,837 articles collected between the subnational dataset and the national media dataset. The combined categories favor the Accept classification now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiVRzOtP9pNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5b1383ce-6715-4ced-b1bc-df5ae198ed8e"
      },
      "source": [
        "count = frame.groupby('label')['label'].count()\n",
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "Accept    37178\n",
              "Reject    23659\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-e_hIydIbq",
        "colab_type": "text"
      },
      "source": [
        "Now let's add the GSR labels. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXzBZ-4ffwpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "c43887b3-b45f-4945-8e17-309d6d68c5bd"
      },
      "source": [
        "gsr = pd.read_csv(\"My Drive/Data/OCVED/Classifier/predictions_v2/correct_classification.csv\")\n",
        "gsr.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000105001_NAC.txt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000105002_NAC.txt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000106001_NAC.txt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20000106002_NAC.txt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20000106003_NAC.txt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               file_id  correct\n",
              "0  20000105001_NAC.txt        1\n",
              "1  20000105002_NAC.txt        1\n",
              "2  20000106001_NAC.txt        1\n",
              "3  20000106002_NAC.txt        1\n",
              "4  20000106003_NAC.txt        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YD7XgRLgkiX",
        "colab_type": "text"
      },
      "source": [
        "Here we add th GSR labels to the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58NPLxUFsPH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "0d7a90d4-1d5f-49e0-cede-4533085736ff"
      },
      "source": [
        "data = pd.merge(frame, gsr)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000105001_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n Las Margaritas, Chis., 5 Ene (N...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000105002_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 4 Ene (NTX).- La Policí...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000106001_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20000106002_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n Monterrey, NL., 6 Ene (NTX).- L...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20000106003_NAC.txt</td>\n",
              "      <td>Accept</td>\n",
              "      <td>\\n es \\n \\n \\n México, 6 Ene (NTX).- Elementos...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               file_id  ... correct\n",
              "0  20000105001_NAC.txt  ...       1\n",
              "1  20000105002_NAC.txt  ...       1\n",
              "2  20000106001_NAC.txt  ...       1\n",
              "3  20000106002_NAC.txt  ...       1\n",
              "4  20000106003_NAC.txt  ...       1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSLSo4GAg06s",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to clean the text. The example below shows the original structure of the text. There is html code we need to clean out, stop words, accents, and other noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5otbJVz3hEcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "85513eab-991f-4548-bf2d-2a80d1dc5e8a"
      },
      "source": [
        "data['text'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n es \\n \\n \\n México, 4 Ene (NTX).- La Policía Federal Preventiva (PFP) informó que en las últimas 24 horas detuvo a ocho individuos, quienes habían asaltado un camión de pasajeros a mano armada, en las inmediaciones del puerto de Mazatlán, Sinaloa. \\n De acuerdo con el reporte más reciente de esta corporación, también en Nogales, Sonora, se decomisaron 535 kilogramos de mariguana, al detener a una camioneta Suburban Chevrolet por haber cometido una infracción. \\n La PFP precisó que en el caso del asalto al omnibus, propiedad de Transportes Turistar, el conductor Leonardo Nicandro Contreras denunció que a la altura del kilometro 321, de la carretera atamoros-Mazatlán, cuatro individuos portando un arma corta y dos largas detuvieron la unidad para robarlos. \\n Contreras dijo que los asaltantes llevaban el rostro cubierto con pasamontañas y despojaron de sus pertenencias y dinero, por un monto aproximado de 12 mil 600 pesos y 350 dólares, a los pasajeros. \\n De inmediato se procedió a implementar un dispositivo de localización y se detuvo a Rogelio Vizcarra Mancilla, de 22 años de edad; Gustavo Vizcarra Pérez (25), Adolfo Pérez Gaytán (18). \\n Asimismo, a Silvestre Mancinas Venegas (24), Fernando Gaytán Labrador (17), Gabriel Sarabia Sarabia (16), y José Guadalupe ancinas Venegas y Diego Ramírez Pérez, ambos de 20 años. \\n Asimismo les fueron decomisadas dos armas largas AK-47 y una corta calibre 0.22 Star, así como 37 cartuchos útiles, y fueron remitidos al Ministerio Público en Concordi, Sinaloa. \\n Además, en el kilómetro 119 de la carretera Tijuana-Playa General se detuvo a una camioneta Suburban, Chevrolet, por una infracción, cuyos ocupantes se dieron a la fuga. \\n Al hacer la revisión de rigor se localizaron 145 paquetes de mariguana, que pesaban 535 kilogramos del estupefaciente, por lo que la denuncia se levantó ante el Ministerio Público Federal en Nogales. \\n NTX/ERM/MER/ERH AZI 15:29 04/01/2000 \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdMNcl1ehY_r",
        "colab_type": "text"
      },
      "source": [
        "Additional packages for cleaning out the text and starting the machine learning pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C535aNp2Hz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "#from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import xgboost\n",
        "from sklearn import model_selection, naive_bayes, svm, linear_model, decomposition, ensemble\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MWfRQFRtQW1",
        "colab_type": "text"
      },
      "source": [
        "We use the Spacy libraries Spanish language lemmatizer to reduce words to their lemma, reducing the size of the overall dictionary further down the pipeline. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlXbN1zN4GOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install es-lemmatizer\n",
        "!pip install -U spacy\n",
        "!sudo python -m spacy download es_core_news_sm\n",
        "\n",
        "# Download stopwords dictionary from nltk\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodtI9Yj2MCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stv8HkNFtdio",
        "colab_type": "text"
      },
      "source": [
        "Code below cleans out accents and normalizes text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ivUoHc63arV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "# BEGIN SHAVE_MARKS_LATIN\n",
        "def shave_marks_latin(txt):\n",
        "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
        "    norm_txt = unicodedata.normalize('NFD', txt)  # <1>\n",
        "    latin_base = False\n",
        "    keepers = []\n",
        "    for c in norm_txt:\n",
        "        if unicodedata.combining(c) and latin_base:   # <2>\n",
        "            continue  # ignore diacritic on Latin base char\n",
        "        keepers.append(c)                             # <3>\n",
        "        # if it isn't combining char, it's a new base char\n",
        "        if not unicodedata.combining(c):              # <4>\n",
        "            latin_base = c in string.ascii_letters\n",
        "    shaved = ''.join(keepers)\n",
        "    return unicodedata.normalize('NFC', shaved)   # <5>\n",
        "# END SHAVE_MARKS_LATIN\n",
        "def shave_marks(txt):\n",
        "    \"\"\"Remove all diacritic marks\"\"\"\n",
        "    norm_txt = unicodedata.normalize('NFD', txt)  # <1>\n",
        "    shaved = ''.join(c for c in norm_txt\n",
        "                     if not unicodedata.combining(c))  # <2>\n",
        "    return unicodedata.normalize('NFC', shaved)  # <3>\n",
        "# END SHAVE_MARKS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsAV51CUt3d7",
        "colab_type": "text"
      },
      "source": [
        "Now we load the spacy nlp module, and add the lemmatizer pipe and POS tagger. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdMZTPv03vsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from es_lemmatizer import lemmatize\n",
        "import es_core_news_sm\n",
        "\n",
        "nlp = es_core_news_sm.load()\n",
        "nlp.add_pipe(lemmatize, after=\"tagger\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGnoLxpVt8qQ",
        "colab_type": "text"
      },
      "source": [
        "Below we load the Spanish stopwords dictionary from nltk and we include additional stopwords that generate noise within the documents. By eliminating these recurring words we can make sure the tf-idf dictionary contains relevant terms. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-9oOqOt3nMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "##Creating a list of stop words and adding custom stopwords\n",
        "stop_words = set(stopwords.words(\"spanish\"))\n",
        "##Creating a list of custom stopwords\n",
        "new_words = [\"daily\", \"newspaper\", \"reforma\", \"publication\", \"universal\", \"iv\", \"one\", \"two\", \"august\" , \"excelsior\", \"online\",\n",
        "             \"november\", \"july\", \"september\", \"june\", \"october\", \"december\", \"print\", \"edition\", \"news\", \"milenio\", \"january\", \"international\",\n",
        "             \"march\", \"april\", \"july\", \"february\", \"may\", \"october\", \"el occidental\", \"comments\", \"powered\", \"display\", \"space\", \n",
        "             \"javascript\", \"trackpageview\", \"enablelinktracking\", \"location\", \"protocol\", \"weboperations\", \"settrackerurl\", \"left\", \n",
        "             \"setsiteid\", \"createelement\", \"getelementsbytagname\", \"parentnode\", \"insertbefore\", \"writeposttexto\", \"everykey\", \"passwords\"\n",
        "             \"writecolumnaderechanotas\", \"anteriorsiguente\", \"anteriorsiguiente\", \"writefooter\", \"align\", \"googletag\", \"writeaddthis\", \"writefooteroem\", \n",
        "             \"diario delicias\", \"diario tampico\", \"the associated press\", \"redaccion\" , \"national\", \"diario yucatan\", \"mural\", \"periodico\", \n",
        "             \"new\", \"previously\", \"shown\" , \"a\", \"para\", \"tener\" , \"haber\", \"ser\" , \"mexico city\", \"states\", \"city\", \"and\", \"elsolde\", \"recomendamos\", \n",
        "            \"diario chihuahua\" , \"diario juarez\" , \"el norte\", \"voz frontera\" , \"regional\" , \"de\"  , \"el sol\" , \"el\" , \"sudcaliforniano\" , \"washington\",\n",
        "            \"union morelos\", \"milenio\" , \"notimex\", \"el financiero\" , \"financiero\" , \"forum magazine\" , \"economista\" , \"gmail\" , \"financial\", \"el\" , \"de\",\n",
        "             \"la\", \"del\", \"de+el\" , \"a+el\" , \"shortcode\" , \"caption\", \"cfcfcf\", \"float\", \"item\", \"width\", \"follow\", \"aaannnnn\", \"gmannnnn\", \n",
        "             \"dslnnnnn\", \"jtjnnnnn\", \"lcgnnnnn\", \"jgcnnnnn\", \"vhannnnn\",  \"mtc\", \"eleconomista\", \"monitoreoif\", \"infosel\", \"gallery\", \n",
        "             \"heaven\", \"div\", \"push\" , \"translate\", \"google\"]\n",
        "stop_words = stop_words.union(new_words)\n",
        "stop_words = shave_marks(repr(stop_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drt8W3jauIe3",
        "colab_type": "text"
      },
      "source": [
        "The below command builds the corpus. It removes punctuations, tags, special characters, white space, and then extracts the lemma of each word, then removes accents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8tWpV6H0JN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNBmm6bL2MsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b03ae40ec7094714a74d22562d21a11c"
          ]
        },
        "outputId": "da762c5d-34bf-4263-da91-805d13853917"
      },
      "source": [
        "corpus = []\n",
        "for i in (dataset.itertuples()): #tqdm\n",
        "    text = shave_marks_latin(i.text)\n",
        "    #Remove punctuations\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    #Convert to lowercase\n",
        "    #text = shave_marks_latin(text)\n",
        "    #text = text.lower()\n",
        "    #remove tags\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    #Lemmatisation\n",
        "    doc = nlp(text)\n",
        "    text = [token.lemma_ for token in doc if token.lemma_ not in stop_words] \n",
        "    text = \" \".join(text)\n",
        "    text = shave_marks(text)\n",
        "    label = i.correct\n",
        "    file_id = i.file_id\n",
        "    corpus.append({ 'text': text,  'label': label  , 'file_id': file_id })\n",
        "print (\"done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b03ae40ec7094714a74d22562d21a11c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YS-7mA2ual3",
        "colab_type": "text"
      },
      "source": [
        "The cleaning process can take over an hour on this dataset. I tried speeding it up using mapping instead but the lemmatization was being inconsistent. So instead I use a regular loop, it is easier to see which articles cause trouble with this method. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAYeur7R36zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(corpus)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYGkCGdX5-0z",
        "colab_type": "text"
      },
      "source": [
        "Given how long it takes to preprocess the text, we save it into a csv for pulling it in later in other scripts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET3r8ILM6m2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.to_csv('/content/drive/My Drive/Data/OCVED/Classifier/universe/preprocessed_text.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTW9QRKT6iIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "42868cf5-a290-4b52-ffca-b4332a781fb5"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Data/OCVED/Classifier/universe/preprocessed_text.csv')\n",
        "data = data[[\"file_id\", \"text\"]]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000105001_NAC.txt</td>\n",
              "      <td>margaritas chis ntx elementos ejercito exicano...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000105002_NAC.txt</td>\n",
              "      <td>ntx policia federal preventiva pfp informo ult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000106001_NAC.txt</td>\n",
              "      <td>ntx elementos policia judicial federal pjf ase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20000106002_NAC.txt</td>\n",
              "      <td>monterrey ntx policia ministerial reporto homb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20000106003_NAC.txt</td>\n",
              "      <td>ntx elementos policia judicial federal pjf ase...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               file_id                                               text\n",
              "0  20000105001_NAC.txt  margaritas chis ntx elementos ejercito exicano...\n",
              "1  20000105002_NAC.txt  ntx policia federal preventiva pfp informo ult...\n",
              "2  20000106001_NAC.txt  ntx elementos policia judicial federal pjf ase...\n",
              "3  20000106002_NAC.txt  monterrey ntx policia ministerial reporto homb...\n",
              "4  20000106003_NAC.txt  ntx elementos policia judicial federal pjf ase..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nHSdELA6GD8",
        "colab_type": "text"
      },
      "source": [
        "Assign the GSR labels for safe measure. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTNt9554644Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "17c057df-08a7-455d-d191-34c3b10759a8"
      },
      "source": [
        "data = pd.merge(data, gsr, on = \"file_id\").rename(columns= {\"correct\":\"label\"})\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000105001_NAC.txt</td>\n",
              "      <td>margaritas chis ntx elementos ejercito exicano...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000105002_NAC.txt</td>\n",
              "      <td>ntx policia federal preventiva pfp informo ult...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000106001_NAC.txt</td>\n",
              "      <td>ntx elementos policia judicial federal pjf ase...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20000106002_NAC.txt</td>\n",
              "      <td>monterrey ntx policia ministerial reporto homb...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20000106003_NAC.txt</td>\n",
              "      <td>ntx elementos policia judicial federal pjf ase...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               file_id  ... label\n",
              "0  20000105001_NAC.txt  ...     1\n",
              "1  20000105002_NAC.txt  ...     1\n",
              "2  20000106001_NAC.txt  ...     1\n",
              "3  20000106002_NAC.txt  ...     1\n",
              "4  20000106003_NAC.txt  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnxaQExBuosM",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMvD-N7aulO1",
        "colab_type": "text"
      },
      "source": [
        "In this section we use the 5 most common algorithms for text classification. Naive-Bayes, Logistic Regression, Support-Vector Machines, Random Forest, and Extreme Gradient Boosting. For each model, two strategies are used to evalaute their performance: The first uses 90% of training data and 10% for the validation set, this allows the model to learn from a larger subsample of data. The second uses a k-fold cross validation approach, where we split the data into 5 different folds, and train 4 different models on this data, using the next fold as the validation set. This produces multiple performance scores that demosntrate how well the model performs on smaller subsets of data. The paper reports both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N6Za5Ky7B9B",
        "colab_type": "text"
      },
      "source": [
        "The first step is to convert our text into a numerical statistic that weighs the frequency of each word across articles. For this paper we chose term frequency-inverse document frequency. The TfidfVectorizer command automatically calculates these weights, here we cap the number of words to use at 5,000. Earlier we reduced each word to its lemma, this allows the tf-idf to weigh words like \"asaltaron\" the same as \"asaltar\" thus allowing more room for a more diverse dictionary. Tf-idf helps reflect how important a word is in the context of the entire document and within the whole collection of documents. These weights are reflected in a numeric matrix for each article. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X4XPshH-Ka1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(data['text'])\n",
        "X = Tfidf_vect.transform(data['text'])\n",
        "Y = data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgGk75QsCiJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "Y = Encoder.fit_transform(data['label']) # confirm this works "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODHTW-7V9IqY",
        "colab_type": "text"
      },
      "source": [
        "This is what article 1 above looks like after being transformed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IVeUbOI8AWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "29d08e80-ec75-4c86-b916-d113461d3180"
      },
      "source": [
        "print(X[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 4998)\t0.12696455339208565\n",
            "  (0, 4875)\t0.11085207796774008\n",
            "  (0, 4749)\t0.10904631456121533\n",
            "  (0, 4678)\t0.07483627627218864\n",
            "  (0, 4464)\t0.06786308207076301\n",
            "  (0, 4359)\t0.11022809036411535\n",
            "  (0, 4333)\t0.07393382056432098\n",
            "  (0, 4294)\t0.09574256488986035\n",
            "  (0, 4153)\t0.06905832872132098\n",
            "  (0, 3992)\t0.04072028376000164\n",
            "  (0, 3963)\t0.10006890937100248\n",
            "  (0, 3911)\t0.08252630430208133\n",
            "  (0, 3779)\t0.11324146113609339\n",
            "  (0, 3775)\t0.06379221646792467\n",
            "  (0, 3755)\t0.08766514068672171\n",
            "  (0, 3705)\t0.030600413300888477\n",
            "  (0, 3694)\t0.0702770454357659\n",
            "  (0, 3676)\t0.2870360207784892\n",
            "  (0, 3675)\t0.10316416354605946\n",
            "  (0, 3642)\t0.0772596523524065\n",
            "  (0, 3608)\t0.033560741914438606\n",
            "  (0, 3578)\t0.07135467001391413\n",
            "  (0, 3497)\t0.06333100647826001\n",
            "  (0, 3389)\t0.09254105791792451\n",
            "  (0, 3307)\t0.13452900522902628\n",
            "  :\t:\n",
            "  (0, 1721)\t0.05384101980644171\n",
            "  (0, 1547)\t0.05430208803402592\n",
            "  (0, 1527)\t0.039632525457918566\n",
            "  (0, 1517)\t0.2500660168350958\n",
            "  (0, 1516)\t0.09276197108669401\n",
            "  (0, 1498)\t0.09030476378424362\n",
            "  (0, 1443)\t0.06269295960565341\n",
            "  (0, 1440)\t0.09803866467433635\n",
            "  (0, 1434)\t0.09185115552435034\n",
            "  (0, 1422)\t0.09030476378424362\n",
            "  (0, 1366)\t0.03856138555352621\n",
            "  (0, 1322)\t0.09211704029752042\n",
            "  (0, 1313)\t0.4622201689416637\n",
            "  (0, 1262)\t0.055985233907984114\n",
            "  (0, 1144)\t0.09596813967953041\n",
            "  (0, 1102)\t0.11595311983730641\n",
            "  (0, 1099)\t0.05157729531650718\n",
            "  (0, 1096)\t0.07698834944047579\n",
            "  (0, 932)\t0.10659802151535125\n",
            "  (0, 750)\t0.10403731408524676\n",
            "  (0, 271)\t0.19615091394907455\n",
            "  (0, 158)\t0.12230449376830621\n",
            "  (0, 94)\t0.05548992675616259\n",
            "  (0, 64)\t0.10599389251152129\n",
            "  (0, 63)\t0.08571731217729418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAfiNDrk9P57",
        "colab_type": "text"
      },
      "source": [
        "Now we split training and test data for the first estimation method. Here 90% of articles are used as training data and 10% are held out for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIoehqMa6KXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(X,Y,test_size=0.10) #,test_size=0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5MMzPuYvNRk",
        "colab_type": "text"
      },
      "source": [
        "Let's confirm how many of each label are in the training and test data sets. feel free to play around with this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfaX7A3d_H6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a792619-7446-4bd8-f829-a7217620357a"
      },
      "source": [
        "Train_Y\n",
        "unique, counts = np.unique(Test_Y, return_counts=True)\n",
        "dict(zip(unique, counts))\n",
        "#unique, counts = np.unique(Train_Y, return_counts=True)\n",
        "#dict(zip(unique, counts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2512, 1: 3569}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As6Bj7ZJvgbQ",
        "colab_type": "text"
      },
      "source": [
        "This is the first algorithm. This is a Naive Bayes classifier. It will print out the accuracy score of the algorithm based on the training data TFIDF on the test data. We also print other measures of performance for reference, for the paper we use F1 across all models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0QZ8A-p--b7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "93dd3050-c6f5-4c88-d494-9de7e4b7cf16"
      },
      "source": [
        "# fit the training dataset on the NB classifier\n",
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(Train_X,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(Test_Y, predictions_NB)*100)\n",
        "print(\"Naive Bayes Precision Score -> \",precision_score( Test_Y, predictions_NB) *100)\n",
        "print(\"Naive Bayes Recall Score -> \",recall_score( Test_Y, predictions_NB) *100)\n",
        "print(\"Naive Bayes F1 Score -> \",f1_score( Test_Y, predictions_NB) *100)\n",
        "\n",
        "print(\"Naive Bayes Precision, Recall, and F1 by Label -> \",precision_recall_fscore_support( Test_Y, predictions_NB))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  89.3603025818122\n",
            "Naive Bayes Precision Score ->  87.55784061696657\n",
            "Naive Bayes Recall Score ->  95.43289436817035\n",
            "Naive Bayes F1 Score ->  91.32591500201099\n",
            "Naive Bayes Precision, Recall, and F1 by Label ->  (array([0.92560475, 0.87557841]), array([0.80732484, 0.95432894]), array([0.86242824, 0.91325915]), array([2512, 3569]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08wXGl1M9yCc",
        "colab_type": "text"
      },
      "source": [
        "Next is the cross validation for the NB model. First, we create a dataframe to store the scores for building out the tables in our paper. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAfRcyv14UDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "saved_scores = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXJoGjs83-IJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "9dab4b51-cfac-4a0a-b491-d81fb0ed0d97"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import pandas as pd\n",
        "# This is where we specify how many folds to use. 5 are specified with 10% left out for final validation\n",
        "cv = ShuffleSplit(n_splits=5, test_size=0.1, random_state=1000)\n",
        "\n",
        "# cross-validate\n",
        "scores = cross_val_score(Naive,\n",
        "                        X,\n",
        "                        Y,\n",
        "                        cv=cv,\n",
        "                         scoring='f1') # Calculating F1 score\n",
        "saved_scores[\"NB_tfidf\"] = scores\n",
        "print(saved_scores[\"NB_tfidf\"])\n",
        "print(\"Average F1 across folds:\" ,saved_scores[\"NB_tfidf\"].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.912360\n",
            "1    0.914939\n",
            "2    0.911957\n",
            "3    0.916314\n",
            "4    0.918840\n",
            "Name: NB_tfidf, dtype: float64\n",
            "Average F1 across folds: 0.9148819254082501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8DApYH8-JL6",
        "colab_type": "text"
      },
      "source": [
        "The NB model performs fairly similar across folds as compared to the more complete model above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHxYAs5KvsGk",
        "colab_type": "text"
      },
      "source": [
        "The below uses a support vector machine (SVM) classifier. Same as above, it prints variosu performance scores for how well the training algorithm perfoms using 90% of articles on the test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5qt43R_Rrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "3778c9fa-5925-4ef2-b573-9a09bac1044b"
      },
      "source": [
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.LinearSVC(C=1.0)\n",
        "SVM.fit(Train_X,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
        "print(\"SVM Precision Score -> \",precision_score( Test_Y, predictions_SVM) *100)\n",
        "print(\"SVM Recall Score -> \",recall_score( Test_Y, predictions_SVM) *100)\n",
        "print(\"SVM F1 Score -> \",f1_score( Test_Y, predictions_SVM) *100)\n",
        "\n",
        "print(\"SVM Precision, Recall, and F1 by Label -> \",precision_recall_fscore_support( Test_Y, predictions_SVM))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  93.60302581812202\n",
            "SVM Precision Score ->  94.04432132963989\n",
            "SVM Recall Score ->  95.12468478565424\n",
            "SVM F1 Score ->  94.58141802479454\n",
            "SVM Precision, Recall, and F1 by Label ->  (array([0.92958316, 0.94044321]), array([0.91441083, 0.95124685]), array([0.92193458, 0.94581418]), array([2512, 3569]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlGbCj-G-bif",
        "colab_type": "text"
      },
      "source": [
        "This model performs really well! Let's see how well it does across folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQkaWLk3I3Xq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7c868fcd-6bd7-4c94-a979-64c72f6c349e"
      },
      "source": [
        "# cross-validate\n",
        "scores = cross_val_score(SVM,\n",
        "                        X,\n",
        "                        Y,\n",
        "                        cv=cv,\n",
        "                         scoring='f1')\n",
        "saved_scores[\"SVM_tfidf\"] = scores\n",
        "print(saved_scores[\"SVM_tfidf\"])\n",
        "print(\"Average F1 across folds:\" ,saved_scores[\"SVM_tfidf\"].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.951697\n",
            "1    0.944383\n",
            "2    0.950404\n",
            "3    0.948476\n",
            "4    0.946773\n",
            "Name: SVM_tfidf, dtype: float64\n",
            "Average F1 across folds: 0.9483468431570617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9mmSXWo-gxH",
        "colab_type": "text"
      },
      "source": [
        "The SVM is learning the feautres of our data really well. Even across folds it is averaging .94 F1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCC_TnAM-uAy",
        "colab_type": "text"
      },
      "source": [
        "Next we used a simple logistic regression. Again we are printing out different performance scores using 90% training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd0E-27RDiqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "77b41f21-0039-4abf-b0ec-f8061c5cfd5f"
      },
      "source": [
        "# Classifier - Algorithm - Logistic Regression\n",
        "# fit the training dataset on the classifier\n",
        "Linear = linear_model.LogisticRegression()\n",
        "Linear.fit(Train_X,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_Linear = Linear.predict(Test_X)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(predictions_Linear, Test_Y)*100)\n",
        "\n",
        "print(\"Logistic Regression Precision Score -> \",precision_score( Test_Y, predictions_Linear) *100)\n",
        "print(\"Logistic Regression Recall Score -> \",recall_score( Test_Y, predictions_Linear) *100)\n",
        "print(\"Logistic Regression F1 Score -> \",f1_score( Test_Y, predictions_Linear) *100)\n",
        "\n",
        "print(\"Logistic Regression Precision, Recall, and F1 by Label -> \",precision_recall_fscore_support( Test_Y, predictions_Linear))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy Score ->  93.52080249958888\n",
            "Logistic Regression Precision Score ->  93.57672248147132\n",
            "Logistic Regression Recall Score ->  95.51695152703839\n",
            "Logistic Regression F1 Score ->  94.53688297282307\n",
            "Logistic Regression Precision, Recall, and F1 by Label ->  (array([0.93437244, 0.93576722]), array([0.90684713, 0.95516952]), array([0.92040404, 0.94536883]), array([2512, 3569]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nla2MLgh_Inx",
        "colab_type": "text"
      },
      "source": [
        "Let's see how well it does across folds. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X1C1wXcJNQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "e43e2400-7e20-4f54-8414-9a685ae24fb6"
      },
      "source": [
        "# cross-validate\n",
        "scores = cross_val_score(Linear,\n",
        "                        X,\n",
        "                        Y,\n",
        "                        cv=cv,\n",
        "                         scoring='f1')\n",
        "saved_scores[\"LR_tfidf\"] = scores\n",
        "print(saved_scores[\"LR_tfidf\"])\n",
        "print(\"Average F1 across folds:\" ,saved_scores[\"LR_tfidf\"].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.949662\n",
            "1    0.949437\n",
            "2    0.947398\n",
            "3    0.950157\n",
            "4    0.949925\n",
            "Name: LR_tfidf, dtype: float64\n",
            "Average F1 across folds: 0.9493155995636389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Dh9GO5_NVD",
        "colab_type": "text"
      },
      "source": [
        "Again averaging a really good .94 F1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RURfRr6b_Qyv",
        "colab_type": "text"
      },
      "source": [
        "Next we try a couple of ensemble methods. The first is a random forest classifier using the 90% training data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI0c3OaQJvCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "6888d38a-3956-478d-a3b3-c5179fba7ab0"
      },
      "source": [
        "\n",
        "# Classifier - Algorithm - Random Forest\n",
        "# fit the training dataset on the classifier\n",
        "RForest = ensemble.RandomForestClassifier()\n",
        "RForest.fit(Train_X,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_RForest = RForest.predict(Test_X)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Random Forest Accuracy Score -> \",accuracy_score(predictions_RForest, Test_Y)*100)\n",
        "\n",
        "print(\"Random Forest Precision Score -> \",precision_score( Test_Y, predictions_RForest) *100)\n",
        "print(\"Random Forest Recall Score -> \",recall_score( Test_Y, predictions_RForest) *100)\n",
        "print(\"Random Forest F1 Score -> \",f1_score( Test_Y, predictions_RForest) *100)\n",
        "\n",
        "print(\"Random Forest Precision, Recall, and F1 by Label -> \",precision_recall_fscore_support( Test_Y, predictions_RForest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy Score ->  91.0541029435948\n",
            "Random Forest Precision Score ->  88.93178893178893\n",
            "Random Forest Recall Score ->  96.80582796301485\n",
            "Random Forest F1 Score ->  92.7019050174403\n",
            "Random Forest Precision, Recall, and F1 by Label ->  (array([0.94808743, 0.88931789]), array([0.82882166, 0.96805828]), array([0.884452  , 0.92701905]), array([2512, 3569]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_7xwjaf_hVy",
        "colab_type": "text"
      },
      "source": [
        "It does not do as well as the linear models, but still great performance. Let's see how well it does across folds. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNLvANfiKeBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f52662fa-141e-44d0-f3e0-51607f824360"
      },
      "source": [
        "# cross-validate\n",
        "scores = cross_val_score(RForest,\n",
        "                        X,\n",
        "                        Y,\n",
        "                        cv=cv,\n",
        "                         scoring='f1')\n",
        "saved_scores[\"RF_tfidf\"] = scores\n",
        "print(saved_scores[\"RF_tfidf\"])\n",
        "print(\"Average F1 across folds:\" ,saved_scores[\"RF_tfidf\"].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.929736\n",
            "1    0.928249\n",
            "2    0.926358\n",
            "3    0.928036\n",
            "4    0.930701\n",
            "Name: RF_tfidf, dtype: float64\n",
            "Average F1 across folds: 0.9286158236834702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06NQGCcX_yHK",
        "colab_type": "text"
      },
      "source": [
        "Finally, we run an extreme gradient boosting model. The first using the 90% training data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DD07T_9MAs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "4d310fc5-423f-4990-84c6-7ea53d141b2a"
      },
      "source": [
        "# Classifier - Algorithm - Extereme Gradient Boosting\n",
        "# fit the training dataset on the classifier\n",
        "xgboost = xgboost.XGBClassifier()\n",
        "xgboost.fit(Train_X,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_XGBoost = xgboost.predict(Test_X)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Extereme Gradient Boosting Accuracy Score -> \",accuracy_score(predictions_XGBoost, Test_Y)*100)\n",
        "\n",
        "print(\"Extereme Gradient Boosting Precision Score -> \",precision_score( Test_Y, predictions_XGBoost) *100)\n",
        "print(\"Extereme Gradient Boosting Recall Score -> \",recall_score( Test_Y, predictions_XGBoost) *100)\n",
        "print(\"Extereme Gradient Boosting F1 Score -> \",f1_score( Test_Y, predictions_XGBoost) *100)\n",
        "\n",
        "print(\"Extereme Gradient Boosting Precision, Recall, and F1 by Label -> \",precision_recall_fscore_support( Test_Y, predictions_XGBoost))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extereme Gradient Boosting Accuracy Score ->  87.69939154744286\n",
            "Extereme Gradient Boosting Precision Score ->  89.0179806362379\n",
            "Extereme Gradient Boosting Recall Score ->  90.16531241244046\n",
            "Extereme Gradient Boosting F1 Score ->  89.58797327394208\n",
            "Extereme Gradient Boosting Precision, Recall, and F1 by Label ->  (array([0.85766423, 0.89017981]), array([0.8419586 , 0.90165312]), array([0.84973885, 0.89587973]), array([2512, 3569]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFKULk_5_6Z2",
        "colab_type": "text"
      },
      "source": [
        "Let's compare across folds. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFIPsL3pMd8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "17fbf78d-6198-4018-a952-8ebb99694bdc"
      },
      "source": [
        "# cross-validate\n",
        "scores = cross_val_score(xgboost,\n",
        "                        X,\n",
        "                        Y,\n",
        "                        cv=cv,\n",
        "                         scoring='f1')\n",
        "saved_scores[\"XGB_tfidf\"] = scores\n",
        "print(saved_scores[\"XGB_tfidf\"])\n",
        "print(\"Average F1 across folds:\" ,saved_scores[\"XGB_tfidf\"].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.905295\n",
            "1    0.896752\n",
            "2    0.901283\n",
            "3    0.902095\n",
            "4    0.902365\n",
            "Name: XGB_tfidf, dtype: float64\n",
            "Average F1 across folds: 0.9015580215307324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGlUbRsu_8cn",
        "colab_type": "text"
      },
      "source": [
        "Not as great as the others. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-PN6sm0M83n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "9561881c-3e2e-4418-f1e3-fff0abde7bfe"
      },
      "source": [
        "saved_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NB_tfidf</th>\n",
              "      <th>SVM_tfidf</th>\n",
              "      <th>LR_tfidf</th>\n",
              "      <th>RF_tfidf</th>\n",
              "      <th>XGB_tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.912360</td>\n",
              "      <td>0.951697</td>\n",
              "      <td>0.949662</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.905295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.914939</td>\n",
              "      <td>0.944383</td>\n",
              "      <td>0.949437</td>\n",
              "      <td>0.926887</td>\n",
              "      <td>0.896752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.911957</td>\n",
              "      <td>0.950404</td>\n",
              "      <td>0.947398</td>\n",
              "      <td>0.927948</td>\n",
              "      <td>0.901283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.916314</td>\n",
              "      <td>0.948476</td>\n",
              "      <td>0.950157</td>\n",
              "      <td>0.930104</td>\n",
              "      <td>0.902095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.918840</td>\n",
              "      <td>0.946773</td>\n",
              "      <td>0.949925</td>\n",
              "      <td>0.928704</td>\n",
              "      <td>0.902365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NB_tfidf  SVM_tfidf  LR_tfidf  RF_tfidf  XGB_tfidf\n",
              "0  0.912360   0.951697  0.949662  0.925926   0.905295\n",
              "1  0.914939   0.944383  0.949437  0.926887   0.896752\n",
              "2  0.911957   0.950404  0.947398  0.927948   0.901283\n",
              "3  0.916314   0.948476  0.950157  0.930104   0.902095\n",
              "4  0.918840   0.946773  0.949925  0.928704   0.902365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDbekCZT__vZ",
        "colab_type": "text"
      },
      "source": [
        "Here we can compare across models. Please note that each time this is run the validation set is different so these numbers may not match up perfectly with the paper. Regardless, after multiple runs the logistic regression consistently out performed all the other models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtM6IFtVv7Wp",
        "colab_type": "text"
      },
      "source": [
        "# Topic Modelling\n",
        "\n",
        "In this next section we run a Latent Dirichlet Allocation model to build topic summaries to better demonstrate the overrall themes captured in our subsample of data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3wdZayJwNeg",
        "colab_type": "text"
      },
      "source": [
        "Here we switch to counter vectorizer that weighs words within the individual document rather than the whole collection. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0OSGDFAJ0cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(data['text'])\n",
        "\n",
        "# transform \n",
        "xcount =  count_vect.transform(data['text'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05b8YZ8JxTT8",
        "colab_type": "text"
      },
      "source": [
        "Below I use latent Dirichlet allocation to extract topic summaries for the entire data set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eo4cvRcKNS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train a LDA Model\n",
        "import numpy\n",
        "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
        "X_topics = lda_model.fit_transform(xcount)\n",
        "topic_word = lda_model.components_ \n",
        "vocab = count_vect.get_feature_names()\n",
        "\n",
        "# view the topic models\n",
        "n_top_words = 10\n",
        "topic_summaries = []\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
        "    topic_summaries.append(' '.join(topic_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJqadumbxdOl",
        "colab_type": "text"
      },
      "source": [
        "Below I print out the topic summaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iO-EwQmKGFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a051cb-1000-4aba-e7e5-238fdea5273c"
      },
      "source": [
        "topic_summaries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['peso millon dinero unidos dolar ninos internacional aeropuerto valor mexicano',\n",
              " 'pgj naucalpan paciente tlalnepantla enfermedad nezahualcoyotl facebook tratamiento personaje alcaldesa',\n",
              " 'arma fuego cartucho vehiculo asegurar calibrar tres cargador largo calibre',\n",
              " 'hombre policia colonia calle hora hecho persona lugar encontrar ciudad',\n",
              " 'decir hacer poder seguridad dar ir municipal parte ciudad realizar',\n",
              " 'municipio cuerpo encontrar guerrero michoacan comunidad persona localizar estatal cadaver',\n",
              " 'hallan www recomendar toma imputado edomex temperatura https siglo bloquear',\n",
              " 'investigacion delito general detener policia federal procuraduria fiscalia presunto persona',\n",
              " 'gobierno nacional presidente gobernador estatal alcalde partido pais tema local',\n",
              " 'security justice paq function of document cmd true piwik original',\n",
              " 'clandestino fosa interno sustancia centro droga penal litro laboratorio penitenciario',\n",
              " 'nuevo leon tamaulipas monterrey candidato san reynosa coahuila garza laredo',\n",
              " 'sexual cae noticia actriz musica vidrio festejo precaucion exposicion ninas',\n",
              " 'cartel grupo lider criminal organizacion jalisco droga zetas integrante guzman',\n",
              " 'estudiante migrantes alumno maestro acumulado bloqueo hogar cadena colegio escolar',\n",
              " 'cuernavaca educacion genero tepito actor vehicular cdmx eje migrante libro',\n",
              " 'derechos comision mx tribunal poder caso organizacion reservados abogado desaparicion',\n",
              " 'menor mujer hijo victima familia edad secuestro padre madre libertad',\n",
              " 'federal droga vehiculo agente mariguana policia detener publico kilo cocaina',\n",
              " 'militar nacional ejercito secretaria mexicano personal zona marina sedena defensa']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOVNEt5LnQ8M",
        "colab_type": "text"
      },
      "source": [
        "# Saving the Model\n",
        "\n",
        "The final step is to save the best performing model for its use on the universe of articles. There is an additional script that uses this training data with transformer models like BERT and another using convolutional neural networks. The logistic regression outperformed the other models which is why we are saving it below for use on the full list of articles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW7d7Y9kMPPN",
        "colab_type": "text"
      },
      "source": [
        "Let's save the output of our algorithm as a usable file for the universe of articles. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUG87oYDBau9",
        "colab_type": "text"
      },
      "source": [
        "First I'm going to save the encoder as a pickle file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5vFNYHZBeu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "#exporting the departure encoder\n",
        "output = open('/content/drive/My Drive/Data/OCVED/Classifier/algorithm/OCVED_encoder_v2.pkl', 'wb')\n",
        "pickle.dump(Encoder, output)\n",
        "output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6XffcpoCGNz",
        "colab_type": "text"
      },
      "source": [
        "Let's test the pickle file, see if it saved correctly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ZcHTaBCJnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9b446150-5556-4a08-d086-105348a00f9a"
      },
      "source": [
        "pkl_file = open('/content/drive/My Drive/Data/OCVED/Classifier/algorithm/OCVED_encoder_v2.pkl', 'rb')\n",
        "encoder = pickle.load(pkl_file) \n",
        "pkl_file.close()\n",
        "\n",
        "valid_encoder = encoder.inverse_transform(Train_Y)\n",
        "valid_encoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHh2AYEqIvi8",
        "colab_type": "text"
      },
      "source": [
        "Let's run the LR one more time to confirm it does well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5tTMZpcC5lY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "2abff27b-3b59-48a4-b161-5fbf17df7189"
      },
      "source": [
        "# Classifier - Algorithm - Logistic Regression\n",
        "# fit the training dataset on the classifier\n",
        "Linear = linear_model.LogisticRegression()\n",
        "Linear.fit(Train_X,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_Linear = Linear.predict(Test_X)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(predictions_Linear, Test_Y)*100)\n",
        "\n",
        "print(\"Logistic Regression Precision Score -> \",precision_score( Test_Y, predictions_Linear) *100)\n",
        "print(\"Logistic Regression Recall Score -> \",recall_score( Test_Y, predictions_Linear) *100)\n",
        "print(\"Logistic Regression F1 Score -> \",f1_score( Test_Y, predictions_Linear) *100)\n",
        "\n",
        "print(\"Logistic Regression Precision, Recall, and F1 by Label -> \",precision_recall_fscore_support( Test_Y, predictions_Linear))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy Score ->  94.0634764019076\n",
            "Logistic Regression Precision Score ->  94.38386041439476\n",
            "Logistic Regression Recall Score ->  95.7146806745922\n",
            "Logistic Regression F1 Score ->  95.044612216884\n",
            "Logistic Regression Precision, Recall, and F1 by Label ->  (array([0.93576461, 0.9438386 ]), array([0.9163961 , 0.95714681]), array([0.92597909, 0.95044612]), array([2464, 3617]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMGylsFQF2_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6251fa7b-ceb0-4333-ea40-e0edacd4541e"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "from sklearn import metrics\n",
        "# save the model to disk\n",
        "filename = '/content/drive/My Drive/Data/OCVED/Classifier/algorithm/logistic_model_v2.sav'\n",
        "joblib.dump(Linear, filename)\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = joblib.load(filename)\n",
        "result = loaded_model.score(Test_X_Tfidf, Test_Y)\n",
        "print(result)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9406347640190759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vpulHFaHZNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "#count_vect.fit(trainDF['text'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "Tfidf_vect_2 =  Tfidf_vect.fit(trainDF['text'])\n",
        "pickle.dump(Tfidf_vect_2, open(\"/content/drive/My Drive/Data/OCVED/Classifier/algorithm/Tfidf_vect_3.pickle\", \"wb\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIFXigpjIINJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "10f50133-07c1-4912-d897-da6ee6c27bea"
      },
      "source": [
        "print(len(Tfidf_vect_2.vocabulary_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}